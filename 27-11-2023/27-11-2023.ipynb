{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\ok\\iml\\27-11-2023\\27-11-2023.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/ok/iml/27-11-2023/27-11-2023.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39menjoysport.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ok/iml/27-11-2023/27-11-2023.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m concepts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(data\u001b[39m.\u001b[39miloc[:,\u001b[39m0\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/ok/iml/27-11-2023/27-11-2023.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mInstances are:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m,concepts)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\readers.py:1723\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1720\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1722\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1723\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[0;32m   1724\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   1725\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[39mif\u001b[39;00m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype_backend\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[39m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39;49mTextReader(src, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:586\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv(\"enjoysport.csv\")\n",
    "concepts = np.array(data.iloc[:,0:-1])\n",
    "print(\"\\nInstances are:\\n\",concepts)\n",
    "target = np.array(data.iloc[:,-1])\n",
    "print(\"\\nTarget Values are: \",target)\n",
    "\n",
    "def learn(concepts, target):\n",
    "    specific_h = concepts[0].copy()\n",
    "    print(\"\\nInitialization of specific_h and genearal_h\")\n",
    "    print(\"\\nSpecific Boundary: \", specific_h)\n",
    "    general_h = [[\"?\" for i in range(len(specific_h))] for i in range(len(specific_h))]\n",
    "    print(\"\\nGeneric Boundary: \",general_h)\n",
    "\n",
    "    for i, h in enumerate(concepts):\n",
    "        print(\"\\nInstance\", i+1 , \"is \", h)\n",
    "        if target[i] == \"yes\":\n",
    "            print(\"Instance is Positive \")\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x]!= specific_h[x]:\n",
    "                    specific_h[x] ='?'\n",
    "                    general_h[x][x] ='?'\n",
    "\n",
    "        if target[i] == \"no\":\n",
    "            print(\"Instance is Negative \")\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x]!= specific_h[x]:\n",
    "                    general_h[x][x] = specific_h[x]\n",
    "                else:\n",
    "                    general_h[x][x] = '?'\n",
    "\n",
    "        print(\"Specific Bundary after \", i+1, \"Instance is \", specific_h)\n",
    "        print(\"Generic Boundary after \", i+1, \"Instance is \", general_h)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    indices = [i for i, val in enumerate(general_h) if val == ['?', '?', '?', '?', '?', '?']]\n",
    "    for i in indices:\n",
    "        general_h.remove(['?', '?', '?', '?', '?', '?'])\n",
    "    return specific_h, general_h\n",
    "\n",
    "s_final, g_final = learn(concepts, target)\n",
    "\n",
    "print(\"Final Specific_h: \", s_final, sep=\"\\n\")\n",
    "print(\"Final General_h: \", g_final, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instances are:\n",
      " [['some' 'small' 'no' 'affordable' 'many']\n",
      " ['many' 'big' 'no' 'expensive' 'one']\n",
      " ['some' 'big' 'always' 'expensive' 'few']\n",
      " ['many' 'medium' 'no' 'expensive' 'many']\n",
      " ['many' 'small' 'no' 'affordable' 'many']]\n",
      "\n",
      "Target Values are:  ['no' 'yes' 'no' 'yes' 'yes']\n",
      "\n",
      "Initialization of specific_h and genearal_h\n",
      "\n",
      "Specific Boundary:  ['some' 'small' 'no' 'affordable' 'many']\n",
      "\n",
      "Generic Boundary:  [['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?']]\n",
      "\n",
      "Instance 1 is  ['some' 'small' 'no' 'affordable' 'many']\n",
      "Instance is Negative \n",
      "Specific Boundary after  1 Instance is  ['some' 'small' 'no' 'affordable' 'many']\n",
      "Generic Boundary after  1 Instance is  [['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?']]\n",
      "\n",
      "\n",
      "\n",
      "Instance 2 is  ['many' 'big' 'no' 'expensive' 'one']\n",
      "Instance is Positive \n",
      "Specific Boundary after  2 Instance is  ['?' '?' 'no' '?' '?']\n",
      "Generic Boundary after  2 Instance is  [['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?']]\n",
      "\n",
      "\n",
      "\n",
      "Instance 3 is  ['some' 'big' 'always' 'expensive' 'few']\n",
      "Instance is Negative \n",
      "Specific Boundary after  3 Instance is  ['?' '?' 'no' '?' '?']\n",
      "Generic Boundary after  3 Instance is  [['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', 'no', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?']]\n",
      "\n",
      "\n",
      "\n",
      "Instance 4 is  ['many' 'medium' 'no' 'expensive' 'many']\n",
      "Instance is Positive \n",
      "Specific Boundary after  4 Instance is  ['?' '?' 'no' '?' '?']\n",
      "Generic Boundary after  4 Instance is  [['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', 'no', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?']]\n",
      "\n",
      "\n",
      "\n",
      "Instance 5 is  ['many' 'small' 'no' 'affordable' 'many']\n",
      "Instance is Positive \n",
      "Specific Boundary after  5 Instance is  ['?' '?' 'no' '?' '?']\n",
      "Generic Boundary after  5 Instance is  [['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', 'no', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?']]\n",
      "\n",
      "\n",
      "Final Specific_h: \n",
      "['?' '?' 'no' '?' '?']\n",
      "Final General_h: \n",
      "[['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', 'no', '?', '?'], ['?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"ok.csv\")\n",
    "concepts = np.array(data.iloc[:,0:-1])\n",
    "print(\"\\nInstances are:\\n\",concepts)\n",
    "target = np.array(data.iloc[:,-1])\n",
    "print(\"\\nTarget Values are: \",target)\n",
    "\n",
    "def learn(concepts, target):\n",
    "    specific_h = concepts[0].copy()\n",
    "    print(\"\\nInitialization of specific_h and genearal_h\")\n",
    "    print(\"\\nSpecific Boundary: \", specific_h)\n",
    "    general_h = [[\"?\" for i in range(len(specific_h))] for i in range(len(specific_h))]\n",
    "    print(\"\\nGeneric Boundary: \",general_h)\n",
    "\n",
    "    for i, h in enumerate(concepts):\n",
    "        print(\"\\nInstance\", i+1 , \"is \", h)\n",
    "        if target[i] == \"yes\":\n",
    "            print(\"Instance is Positive \")\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x]!= specific_h[x]:\n",
    "                    specific_h[x] ='?'\n",
    "                    general_h[x][x] ='?'\n",
    "\n",
    "        if target[i] == \"no\":\n",
    "            print(\"Instance is Negative \")\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x]!= specific_h[x]:\n",
    "                    general_h[x][x] = specific_h[x]\n",
    "                else:\n",
    "                    general_h[x][x] = '?'\n",
    "\n",
    "        print(\"Specific Boundary after \", i+1, \"Instance is \", specific_h)\n",
    "        print(\"Generic Boundary after \", i+1, \"Instance is \", general_h)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    indices = [i for i, val in enumerate(general_h) if val == ['?', '?', '?', '?', '?', '?']]\n",
    "    for i in indices:\n",
    "        general_h.remove(['?', '?', '?', '?', '?', '?'])\n",
    "    return specific_h, general_h\n",
    "\n",
    "s_final, g_final = learn(concepts, target)\n",
    "\n",
    "print(\"Final Specific_h: \", s_final, sep=\"\\n\")\n",
    "print(\"Final General_h: \", g_final, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instance 1 is ['some' 'small' 'no' 'affordable' 'many']\n",
      "Instance is Negative \n",
      "Specific Boundary after 1 Instance is ['some' 'small' 'no' 'affordable' 'many']\n",
      "Generic Boundary after 1 Instance is ['?', '?', '?', '?', '?']\n",
      "\n",
      "\n",
      "\n",
      "Instance 2 is ['many' 'big' 'no' 'expensive' 'one']\n",
      "Instance is Positive \n",
      "Specific Boundary after 2 Instance is ['?' '?' 'no' '?' '?']\n",
      "Generic Boundary after 2 Instance is ['?', '?', '?', '?', '?']\n",
      "\n",
      "\n",
      "\n",
      "Instance 3 is ['some' 'big' 'always' 'expensive' 'few']\n",
      "Instance is Negative \n",
      "Specific Boundary after 3 Instance is ['?' '?' 'no' '?' '?']\n",
      "Generic Boundary after 3 Instance is ['?', '?', 'no', '?', '?']\n",
      "\n",
      "\n",
      "\n",
      "Instance 4 is ['many' 'medium' 'no' 'expensive' 'many']\n",
      "Instance is Positive \n",
      "Specific Boundary after 4 Instance is ['?' '?' 'no' '?' '?']\n",
      "Generic Boundary after 4 Instance is ['?', '?', 'no', '?', '?']\n",
      "\n",
      "\n",
      "\n",
      "Instance 5 is ['many' 'small' 'no' 'affordable' 'many']\n",
      "Instance is Positive \n",
      "Specific Boundary after 5 Instance is ['?' '?' 'no' '?' '?']\n",
      "Generic Boundary after 5 Instance is ['?', '?', 'no', '?', '?']\n",
      "\n",
      "\n",
      "Final Specific_h:\n",
      "['?' '?' 'no' '?' '?']\n",
      "Final General_h:\n",
      "['no']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def initialize_hypotheses(concept):\n",
    "    specific_h = concept.copy()\n",
    "    general_h = [\"?\" for _ in range(len(concept))]\n",
    "    return specific_h, general_h\n",
    "\n",
    "def is_positive(instance, target, specific_h):\n",
    "    return target == \"yes\"\n",
    "\n",
    "def is_negative(instance, target, specific_h):\n",
    "    return target == \"no\"\n",
    "\n",
    "def update_hypotheses(instance, target, specific_h, general_h):\n",
    "    if is_positive(instance, target, specific_h):\n",
    "        for i in range(len(specific_h)):\n",
    "            if instance[i] != specific_h[i]:\n",
    "                specific_h[i] = '?'\n",
    "                general_h[i] = '?'\n",
    "    elif is_negative(instance, target, specific_h):\n",
    "        for i in range(len(specific_h)):\n",
    "            if instance[i] != specific_h[i]:\n",
    "                general_h[i] = specific_h[i]\n",
    "            else:\n",
    "                general_h[i] = '?'\n",
    "    return specific_h, general_h\n",
    "\n",
    "def remove_empty_hypotheses(general_h):\n",
    "    return [h for h in general_h if '?' not in h]\n",
    "\n",
    "def learn(concepts, targets):\n",
    "    specific_h, general_h = initialize_hypotheses(concepts[0])\n",
    "\n",
    "    for i, (instance, target) in enumerate(zip(concepts, targets), start=1):\n",
    "        print(\"\\nInstance\", i, \"is\", instance)\n",
    "        \n",
    "        if is_positive(instance, target, specific_h):\n",
    "            print(\"Instance is Positive \")\n",
    "        elif is_negative(instance, target, specific_h):\n",
    "            print(\"Instance is Negative \")\n",
    "\n",
    "        specific_h, general_h = update_hypotheses(instance, target, specific_h, general_h)\n",
    "        \n",
    "        print(\"Specific Boundary after\", i, \"Instance is\", specific_h)\n",
    "        print(\"Generic Boundary after\", i, \"Instance is\", general_h)\n",
    "        print(\"\\n\")\n",
    "\n",
    "    return specific_h, remove_empty_hypotheses(general_h)\n",
    "\n",
    "data = pd.read_csv(\"ok.csv\")\n",
    "concepts = np.array(data.iloc[:, 0:-1])\n",
    "targets = np.array(data.iloc[:, -1])\n",
    "\n",
    "s_final, g_final = learn(concepts, targets)\n",
    "\n",
    "print(\"Final Specific_h:\", s_final, sep=\"\\n\")\n",
    "print(\"Final General_h:\", g_final, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
